{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Lab 1+2: Python, Regression, and PyTorch (beginner; student).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanzil7/automate-spotify-python/blob/master/Lab_1%2B2_Python%2C_Regression%2C_and_PyTorch_(beginner%3B_student).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttj73Ee58VDE"
      },
      "source": [
        "**NOTE**: Please make a personal copy of this notebook by selecting 'File' > 'Save a copy in Drive' in the menu bars above.\n",
        "\n",
        "\n",
        "Overview\n",
        "=====================\n",
        "\n",
        "While programming offers a powerful way to automate repetitive processes, it's only applicable if we are able to precisely specify and program the behavior we want. Machine learning offers us a way to avoid this need for exact specification by only requiring us to specify a goal, and then having an algorithm learn a way to achieve that goal.\n",
        "\n",
        "The machine learning workflow typically consists of the following steps\n",
        "\n",
        "1. Acquire and process data for the problem of interest\n",
        "2. Choose a model\n",
        "3. Define an objective\n",
        "4. Train the model on the training data\n",
        "5. Evaluate the trained model on the test data\n",
        "\n",
        "We will walk through these steps in a simple but realistic setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUL7mIgUhHZN"
      },
      "source": [
        "This lab is a Colab notebook, an interactive Python environment.\n",
        "A notebook consists of multiple text cells (like this one) and code cells. You can make new cells of either type by clicking the \"+\" buttons in the top left corner.\n",
        "\n",
        "You can write code blocks, and then execute the code by highlighting the block then pressing control+enter. Try this with the following cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR6mn19Q8VC9"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ4bKo_ZpHHY"
      },
      "source": [
        "## Python\n",
        "\n",
        "\n",
        "For this lab and much of machine learning, we will use Python for its ease of understanding and large library ecosystem. Let's briefly go over Python syntax and features.\n",
        "\n",
        "Python is an [imperative language](https://en.wikipedia.org/wiki/Imperative_programming) based on [statements](https://en.wikipedia.org/wiki/Statement_(computer_science)). That is, programs in Python consists of lines composed of statements. Among other things, a statement can be:\n",
        "* a single expression, e.g. `5 + 5`\n",
        "* an assignment, e.g. `x = 5`\n",
        "    * variable names can be any length and can consist of uppercase and lowercase letters (A-Z, a-z), digits (0-9), and the underscore character (_), except they cannot start with a digit\n",
        "* a function call, e.g. `print(x)`\n",
        "* make in-line comments by prepending lines with \\#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lAwIxV5qF_O"
      },
      "source": [
        "### Built-in Data Types\n",
        "\n",
        "* Numbers: there are two important numerical types, `int` and `float`\n",
        "  * integers: `1`, `-3`, etc.\n",
        "  * floating-point: `1.0`, `3.14`, etc.\n",
        "* strings: `'apple'`, `\"v\"`\n",
        "* boolean values: `True`, `False`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEu4JTHnrpDG"
      },
      "source": [
        "### Functions\n",
        "\n",
        "Functions are defined with the following syntax:\n",
        "```\n",
        "def function_name(arg1, args2=default2, ...):\n",
        "    # function body\n",
        "    return\n",
        "```\n",
        "Most of the time, your functions should return a value (possibly multiple values, separated by commas) using the `return` keyword, but this isn't a requirement. If you don't explicitly return something, the function will return the special `None` value by default.\n",
        "\n",
        "Functions are called by using the function name followed by parentheses.\n",
        "If you use the function name without parentheses, you are referring to the function itself, as an object.\n",
        "\n",
        "Python contains many built-in functions. Some of these are straightforward math operators, (e.g. `+, -, /, *`), and others must be called using parentheses, such as `print()`, `int()`, `sum()`, or `len()`.\n",
        "\n",
        "**(exercise)** Write a function that takes in two numbers and computes their mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nri12FTCpaNp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1hQYVS-rGL0"
      },
      "source": [
        "### Data Structures\n",
        "\n",
        "Python also has three built-in data structures that are very useful:\n",
        "\n",
        "**Lists** are ordered lists and are created using brackets (`[]`) with comma-separated values. We can access list elements using the list name followed by the index of the element we want to access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7rFwFL0rM8S"
      },
      "source": [
        "# lists\r\n",
        "l = [1, 2, 3]\r\n",
        "print(l[0]) # indexing\r\n",
        "print(l[1])\r\n",
        "print(1[-1]) # negative indexing\r\n",
        "print(l[:2]) # slicing\r\n",
        "\r\n",
        "ll = [1, \"a\", []] # list elements don't need to be the same type\r\n",
        "\r\n",
        "lll = [] # defining empty list, also `list()`\r\n",
        "print(lll)\r\n",
        "lll.append(1) # add to a list\r\n",
        "lll.append(2)\r\n",
        "print(lll)\r\n",
        "print(len(lll)) # get the length\r\n",
        "\r\n",
        "print(ll + lll) # concatenation of two lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVydmiCqkmO"
      },
      "source": [
        "**Dictionaries**, or hash tables, are sets of key-value pairs. We create dictionaries using curly braces (`{}`). We can access the value associated with a particular key by typing the name of the dictionary followed by the key in brackets. The key can be a variable or a literal (strings or numbers).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eV4PAYzriWr"
      },
      "source": [
        "d = {\"apple\": \"a fruit\", \"banana\": \"an herb\", \"monkey\": \"a mammal\"}\r\n",
        "print(len(d)) # number of key-value pairs in d\r\n",
        "print(d[\"apple\"]) # accessing an element\r\n",
        "\r\n",
        "d['broccoli'] = 'a vegetable' # assign a new key-value pair\r\n",
        "del d['apple'] # delete a key-value pair\r\n",
        "print(\"apple\" in d) # check membership\r\n",
        "key = \"banana\"\r\n",
        "print(key in d) # variables as keys\r\n",
        "\r\n",
        "print(d.keys()) # unordered list of keys in the dictionary\r\n",
        "print(d.values()) # unordered list of values in the dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZVcUoCQqmDh"
      },
      "source": [
        "**Tuples** are also ordered lists of items, but unlike lists they cannot be changed (i.e., they're immutable). Tuples are created using parentheses and their elements can also be accessed using brackets.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7mzqXoGreG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb625bd-7015-46ac-b8bf-484f5606ca02"
      },
      "source": [
        "t = (1, 2, \"cow\")\r\n",
        "print(t[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIq03V2Z2Ypd"
      },
      "source": [
        "### Control Flow\r\n",
        "\r\n",
        "Python supports standard control flow keywords such as \r\n",
        "* `if`/`elif`/`else`\r\n",
        "    ```\r\n",
        "    if condition_a:\r\n",
        "      # do something\r\n",
        "    elif condition_b:\r\n",
        "      # do something else\r\n",
        "    else:\r\n",
        "      # do something else instead\r\n",
        "    ```\r\n",
        "    Note that `elif` and `else` are not necessary.\r\n",
        "\r\n",
        "* `for` loops: \r\n",
        "    ``` \r\n",
        "    for iter_name in iterable: # e.g. a list like [1, 2, 3]\r\n",
        "      # do something\r\n",
        "      print(iter_name)\r\n",
        "    ```\r\n",
        "    \r\n",
        "    Note that `iterable` can be any object that can be iterated over in order. Most commonly, `iterable` is a list. Dictionaries are not iterable as they are unordered. A useful built-in function is `range(n)`, which returns an iterable of all integers from 0 to n-1.\r\n",
        "    \r\n",
        "\r\n",
        "### Logic\r\n",
        "\r\n",
        "* equals: `==` or `is`\r\n",
        "    ```\r\n",
        "    x = 5\r\n",
        "    if x is 5:\r\n",
        "      print(\"true\")\r\n",
        "    else:\r\n",
        "      print(\"false\")\r\n",
        "    ```\r\n",
        "* not: `!` or `not`\r\n",
        "    ```\r\n",
        "    x = 5\r\n",
        "    if x != 5:\r\n",
        "      print(\"false\"):\r\n",
        "    elif x is not 8:\r\n",
        "      print(\"true\")\r\n",
        "    ```\r\n",
        "* logical and/or: `and`/`or` or `&&`/`||`\r\n",
        "* greater/less than: `>`/`<`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jecxY-Rs4J78"
      },
      "source": [
        "**(exercises)** \r\n",
        "\r\n",
        "1. Write a function that squares a number if it is greater than 10, otherwise halves it.\r\n",
        "\r\n",
        "2. Write a function that takes in two lists and returns a list of all elements in both lists.\r\n",
        "\r\n",
        "3. Write a function that takes in a list and creates a dictionary where each key is an index and the corresponding value is the list value at that index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPe7jk4UuN7p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_LfC-q7Z0Nf"
      },
      "source": [
        "## Numpy and Other Libraries\n",
        "\n",
        "This lab relies on a number of standard scientific computing Python packages. The most important of these is NumPy (Numerical Python, commonly imported as `np`), which is a Python package for numerical computing. We'll briefly cover common numpy functions and syntax; you can find a more in-depth guide [here](https://numpy.org/doc/stable/user/quickstart.html) and you can always consult the documentation or Google if you're confused about a function.\n",
        "\n",
        "The core object of numpy is the `array`, which is similar an ordinary Python list. Numpy arrays are frequently multi-dimensional (like a list of lists), and we call each dimension an axis.\n",
        "\n",
        "You can create numpy arrays through a variety of ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ89KYLMZ0Nh"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# call np.array on a valid Python list\n",
        "array = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"Array 1:\\n\", array)\n",
        "\n",
        "# initialize an array of all zeroes or ones\n",
        "array = np.zeros((3, 4)) # where (3,4) is the shape of the array\n",
        "print(\"Array 2:\\n\", array)\n",
        "\n",
        "array = np.ones((3, 4, 5)) # where (3, 4, 5) is the shape of the array\n",
        "print(\"Array 3:\\n\", array)\n",
        "\n",
        "# initialize an array from a particular distribution\n",
        "array = np.random.normal(loc=0.0, scale=1.0, size=(3,4))  # uses a normal distribution with a mean at 0 and standard deviation of 1.0\n",
        "print(array_normal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqQwTd1NMmU-"
      },
      "source": [
        "Unlike Python lists, numpy arrays must\r\n",
        "* have the same number of elements along each dimension (e.g. `[[1], [2,3]]` would not be a valid numpy array).\r\n",
        "* have all elements be of the same type\r\n",
        "\r\n",
        "We can check the type and shape (dimensions) of an array using built-in numpy attributes of arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_7fKA1sMW2j",
        "outputId": "2d8b0a5a-820a-45d2-cb5c-e84b94331412"
      },
      "source": [
        "array = np.array([[[1], [2]], [[3], [4]], [[5], [6]]])\r\n",
        "print(\"Data type:\", array.dtype)\r\n",
        "print(\"# dimensions:\", array.ndim)\r\n",
        "print(\"Shape/size of array:\", array.shape)\r\n",
        "print(\"# elements:\", array.size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data type: int64\n",
            "# dimensions: 3\n",
            "Shape/size of array: (3, 2, 1)\n",
            "# elements: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojQsAsG4-amU"
      },
      "source": [
        "We can access specific elements of an array using braces (like Python lists) and colons (slices)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtSHq0kfNvzS",
        "outputId": "67c1b76f-45f8-44de-911d-006a5abbb24e"
      },
      "source": [
        "array = np.arange(24).reshape(4, 6)\r\n",
        "\r\n",
        "print(\"Array:\\n\", array)\r\n",
        "print(\"Element 1, 2: \", array[1, 2]) # access one element\r\n",
        "\r\n",
        "print(\"Column 2:\", array[:, 1]) # access a column, using slice notation (:)\r\n",
        "print(\"Row 1:\", array[0]) # access a row\r\n",
        "\r\n",
        "print(\"2nd-4th row, 1st-3rd col:\\n\", array[1:3, 0:2]) # partial rows and cols\r\n",
        "\r\n",
        "# accessing elements using an array\r\n",
        "print(\"Selecting one element from each row of array using indices in ind:\")\r\n",
        "inds = np.array([0, 2, 0, 1])\r\n",
        "print(array[np.arange(4), inds])  # Prints \"[ 0  8  12 19]\"\r\n",
        "print(\"-----\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array:\n",
            " [[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n",
            "Element 1, 2:  8\n",
            "Column 2: [ 1  7 13 19]\n",
            "Row 1: [0 1 2 3 4 5]\n",
            "2nd-4th row, 1st-3rd col:\n",
            " [[ 6  7]\n",
            " [12 13]]\n",
            "Selecting one element from each row of a using indices in b:\n",
            "[ 0  8 12 19]\n",
            "-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xPLlKYxJ8P6"
      },
      "source": [
        "Numpy arrays contain many useful functions as built-in methods for arrays. For example, one of the most useful is `array.sum()`. Other useful methods include `min(), max(), argmin(), argmax(), mean(), std()`. All of these methods take in an `axis` argument that specifies the dimension along which to perform the operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk7CcR_JJ4p_",
        "outputId": "f5df5192-3ce6-4dc6-e361-e9860885207b"
      },
      "source": [
        "x = np.array([[1,2],[3,4]])\n",
        "print(\"x: \\n\", x)\n",
        "print(\"-----\")\n",
        "print(\"Compute sum of all elements in x: \", np.sum(x))  # Compute sum of all elements; prints \"10\"\n",
        "print(\"-----\")\n",
        "print(\"Compute sum of each column in x:\", np.sum(x, axis=0))  # Compute sum of each column; prints \"[4 6]\"\n",
        "print(\"-----\")\n",
        "print(\"Compute sum of each row in x: \", np.sum(x, axis=1))  # Compute sum of each row; prints \"[3 7]\"\n",
        "print(\"-----\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: \n",
            " [[1 2]\n",
            " [3 4]]\n",
            "-----\n",
            "Compute sum of all elements in x:  10\n",
            "-----\n",
            "Compute sum of each column in x: [4 6]\n",
            "-----\n",
            "Compute sum of each row in x:  [3 7]\n",
            "-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jorliwCSC2D"
      },
      "source": [
        "We can transform arrays using Python built-in math operators, as well as more complex math operators in numpy, such as `np.power(), np.exp(), np.sqrt(), np.cos()`, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy-luRJUSEdL",
        "outputId": "362b4b55-71fb-402f-caed-1bcfc3a031b4"
      },
      "source": [
        "array = np.arange(9).reshape((3,3))\r\n",
        "print(\"Array 1:\\n\", array)\r\n",
        "\r\n",
        "# mathematical transformations\r\n",
        "print(array + 3) # add a constant to every value, broadcasting\r\n",
        "array[0] *= 2 # add a constant to only one row\r\n",
        "print(array)\r\n",
        "print(np.power(array, 2)) # square every element"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array 1:\n",
            " [[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]]\n",
            "[[ 3  4  5]\n",
            " [ 6  7  8]\n",
            " [ 9 10 11]]\n",
            "[[0 2 4]\n",
            " [3 4 5]\n",
            " [6 7 8]]\n",
            "[[ 0  4 16]\n",
            " [ 9 16 25]\n",
            " [36 49 64]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPE0seexUspH"
      },
      "source": [
        "We can also transform the dimensions and shape of arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvhropfrUvyy",
        "outputId": "8351d9dc-c852-4aff-dead-1f6e1568bbce"
      },
      "source": [
        "# reshaping\r\n",
        "array = np.arange(9)\r\n",
        "print(\"Array 0:\\n\", array)\r\n",
        "print(\"Array 0 shape:\", array.shape)\r\n",
        "array = array.reshape(3, 3)\r\n",
        "print(\"Array 0:\\n\", array)\r\n",
        "print(\"Array 0 shape:\", array.shape)\r\n",
        "print()\r\n",
        "\r\n",
        "array1 = np.arange(9).reshape((3,3))\r\n",
        "array2 = np.arange(9, 18).reshape((3, 3))\r\n",
        "print(\"Array 1:\\n\", array1)\r\n",
        "print(\"Array 2:\\n\", array2)\r\n",
        "stack_h = np.hstack((array1, array2))\r\n",
        "stack_v = np.vstack((array1, array2))\r\n",
        "print(\"Horizontally stacked array 1 and array 2:\\n\", stack_h)\r\n",
        "print(\"Vertically stacked array 1 and array 2:\\n\", stack_v)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array 0:\n",
            " [0 1 2 3 4 5 6 7 8]\n",
            "Array 0 shape: (9,)\n",
            "Array 0:\n",
            " [[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]]\n",
            "Array 0 shape: (3, 3)\n",
            "\n",
            "Array 1:\n",
            " [[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]]\n",
            "Array 2:\n",
            " [[ 9 10 11]\n",
            " [12 13 14]\n",
            " [15 16 17]]\n",
            "Horizontally stacked array 1 and array 2:\n",
            " [[ 0  1  2  9 10 11]\n",
            " [ 3  4  5 12 13 14]\n",
            " [ 6  7  8 15 16 17]]\n",
            "Vertically stacked array 1 and array 2:\n",
            " [[ 0  1  2]\n",
            " [ 3  4  5]\n",
            " [ 6  7  8]\n",
            " [ 9 10 11]\n",
            " [12 13 14]\n",
            " [15 16 17]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heXTvKjE_sbH"
      },
      "source": [
        "We can do all the standard matrix operations using these numpy arrays. Here we show addition, transposing a matrix, matrix multiplication, and matrix inversion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgeR0bdR_1fn",
        "outputId": "0cd3f23e-0b70-4422-a01a-304c1036ac32"
      },
      "source": [
        "A = np.random.randint(10, size=(3, 4))\n",
        "B = np.random.randint(10, size=(3, 4))\n",
        "print(\"Matrix A:\\n\", A)\n",
        "print(\"\\nMatrix B:\\n\", B)\n",
        "print(\"\\nA+B:\\n\", A+B)\n",
        "print(\"\\nTranspose B:\\n\", B.transpose())\n",
        "print(\"\\nShape of transpose(B):\", B.transpose().shape)\n",
        "print(\"\\nMatrix multiplication of A and transpose(B):\\n\", np.matmul(A,B.transpose()))\n",
        "\n",
        "C = np.matmul(A,B.transpose())\n",
        "print(\"\\n Invert AB:\", np.linalg.inv(C))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix A:\n",
            " [[3 0 6 6]\n",
            " [5 7 8 5]\n",
            " [8 3 1 8]]\n",
            "\n",
            "Matrix B:\n",
            " [[7 9 4 2]\n",
            " [7 2 3 2]\n",
            " [7 0 2 5]]\n",
            "\n",
            "A+B:\n",
            " [[10  9 10  8]\n",
            " [12  9 11  7]\n",
            " [15  3  3 13]]\n",
            "\n",
            "Transpose B:\n",
            " [[7 7 7]\n",
            " [9 2 0]\n",
            " [4 3 2]\n",
            " [2 2 5]]\n",
            "\n",
            "Shape of transpose(B): (4, 3)\n",
            "\n",
            "Matrix multiplication of A and transpose(B):\n",
            " [[ 57  51  63]\n",
            " [140  83  76]\n",
            " [103  81  98]]\n",
            "\n",
            " Invert (AB): [[-0.1660371  -0.0088139   0.11357341]\n",
            " [ 0.49458575  0.07579955 -0.3767313 ]\n",
            " [-0.23428188 -0.05338706  0.20221607]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpv3nDTaVLbt"
      },
      "source": [
        "**(exercises)** \r\n",
        "\r\n",
        "\r\n",
        "1. Write a function that converts an array of Celsius temperatures into an array of Farenheit temperatures (according to the formula $C = (F - 32) / 1.8$).\r\n",
        "\r\n",
        "2. Write a function that sets the first row of a matrix to zero.\r\n",
        "\r\n",
        "3. Create a 5x5 array of the numbers from 1-25, and then append a row of zeroes to the end.\r\n",
        "\r\n",
        "4. Compute the product of $A$ and $B$, where $A$ is a 2x2 matrix of the first four even numbers squared and $B$ is a 2x2 matrix of the first four odd numbers squared.\r\n",
        "\r\n",
        "5. Write a function that divides each column of a matrix by its standard deviation.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6n5Rx20Vxt-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcSA5Bqaetg3"
      },
      "source": [
        "This lab also relies on the following libraries:\n",
        "* MatPlotLib is a plotting package used to create graphs and figures in order to visualize data and models\n",
        "* Scikit-learn is a high-level machine learning library containing common datasets, models, and transformations for machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFsZOHjreyJV"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFH7BFNeUk2h"
      },
      "source": [
        "# Regression\r\n",
        "\r\n",
        "Regression is the general problem of predicting the value of some quantity of interest given some inputs. Many real-world problems are regression problems, such as predicting\r\n",
        "* how much money a movie will make\r\n",
        "* the score of a basketball game\r\n",
        "* the number of COVID cases\r\n",
        "\r\n",
        "More formally, we describe the regression problem as learning a relationship, or function $f$, between a vector of **input features $x$** and an **output value $y$**. When we evaluate $f$ on a new input $x$, we want the model's prediction $f(x)$ to be close to the actual output $y$.\r\n",
        "\r\n",
        "## Data\r\n",
        "\r\n",
        "Before we discuss what the function $f$ looks like, we will first take a look at the data, which are the ($x$, $y$) pairs. For regression, the output value $y$ will be a scalar number. The input $x$ is a vector, each entry of which we call an **input feature**. An input feature is some property of the underlying problem that we believe might be predictive of the outut. For example, if we are interested in predicting how well someone will score on a test, we might use the number of hours slept the night before as a feature. Though we don't know the exact mathematical relationship between an input feature and the output, we hope that our machine learning methods can learn a function that's close to the true relationship.\r\n",
        "\r\n",
        "For this lab, we'll use a dataset of neighborhood features and try to predict the average house value (in units of 100K) in that neighborhood, though the methods used here will be applicable to any regression dataset you're interested in. We'll load this dataset using Scikit-learn; you can read about it [here](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjzV4GluXkxM"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\r\n",
        "X, y = fetch_california_housing(return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqBKjxHMbAJ3"
      },
      "source": [
        "In using machine learning methods, it's important that we first understand the data we're using to make sure the methods we're using are appropriate for the task at hand.\r\n",
        "\r\n",
        "**(exercise)** Let's first understand how much data we have and what a few examples from the dataset look like. Write code to do the following: \r\n",
        "* Print the first 10 examples\r\n",
        "* Determine the number of data points we have\r\n",
        "* Print the min, max, and median values for a feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUByuXDimjvb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iESYSId0mn0W"
      },
      "source": [
        "Next, let's plot the data to get a sense of what it looks like.\r\n",
        "Since the input consists of multiple features, we'll pick out one feature at a time and see what it looks like compared to the housing price. \r\n",
        "\r\n",
        "**(exercise)** Use the following code to write a function that takes in the index of a feature to look at, and generates the plot for that feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "0DIullDrXylV",
        "outputId": "bffb43ab-4162-4a80-f942-d30a1e1e0748"
      },
      "source": [
        "plt.scatter(X[:,0], y)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qeeDudgg704"
      },
      "source": [
        "Though we will proceed with using this dataset as provided to us, we can apply any transformations to the data that we think will help surface useful signal to our machine learning model. There is a lot of freedom and room for domain expertise in designing input features for any particular task.\n",
        "\n",
        "If you have time, try adding a feature to the dataset by transforming one of the other features (e.g. take log, create a binary feature if a value crosses a certain threshold, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJOSPK-ShqGY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlAAwyaRY3vw"
      },
      "source": [
        "\r\n",
        "## Model\r\n",
        "\r\n",
        "Now that we have looked at our data, we need to pick a type of model to learn from our data.\r\n",
        "For this lab, we will use a simple linear model, where we assume that the relationship between the output variable and each input feature is linear. \r\n",
        "\r\n",
        "Mathematically, we write this model as\r\n",
        "$$ y = f(x) = b + \\sum_{i=1}^m w_i x_i $$\r\n",
        "where $i$ indexes each dimension in the $m$-dimensional input feature vector $x$.\r\n",
        "Together, the $w_i$ and $b$ are called the **weights** or **parameters** of the model.\r\n",
        "If $x$ is 1-dimensional, then we get $y = wx + b$; if $x$ is 2-dimensional, then we get $y = w_1 x_1 + w_2 x_2 + b$; and so forth. \r\n",
        "Alternatively, we can write this as \r\n",
        "$$ y = w \\cdot x $$\r\n",
        "where $w$ is a vector representation of the $w_i$. To properly account for the bias term $b$, we append $b$ to $w$ (so that $w$ is $[w_1; w_2; \\dots; w_m; b]$) and append a 1 to the input features $x$.\r\n",
        "\r\n",
        "**(exercise)** Let's write a function which takes in some weights $w$ and $b$ and an input $x$ and outputs the $y$ computed by this model. You can use a for-loop, but we recommend using a vector product (you might find `np.dot()` useful)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYXQlCJ_r8w6"
      },
      "source": [
        "def linear(x, w, b):\r\n",
        "  raise NotImplementedError\r\n",
        "\r\n",
        "assert linear([1], [10], 10) == 20\r\n",
        "assert linear([1, 1], [1, 1], 0) == 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWFgioDar8J6"
      },
      "source": [
        "\r\n",
        "## Training\r\n",
        "\r\n",
        "In order to use this model, we need to first set the value of the weights. But, we don't know what the ''right'' values are.\r\n",
        "In order to do so, we first need to be able to say what constitutes good weights. Then, we can introduce an **objective function** that measures how good any set of weights are. Given this objective function, the best weights are the ones that maximize (or minimize) the objective function.\r\n",
        "\r\n",
        "For regression, we'll use the **residual sum of squares** (RSS):\r\n",
        "$$ L(w) = \\sum_{d \\in D} (y_d - f(x_d))^2 = \\sum_{d \\in D} (y_d - w \\cdot x_d)^2 $$\r\n",
        "where $D$ is our dataset of $(x ,y)$ pairs. Intuitively, this objective function looks at the distance from our model's predictions to the actual output. To pick the best $w$, then, we want to minimize this objective function.\r\n",
        "\r\n",
        "To minimize this expression, we look at where the gradient (or derivative, in 1-d) of the objective function with respect to the weights is equal to zero and solve for $w$ at that point. Let's first compute the derivative. \r\n",
        "\r\n",
        "For convenience, we'll use a vector product representation of the model and a matrix representation of the data ($X$ is a matrix where each row is a data point $x_i$ and $y$ is a column vector of the corresponding $y_i$).\r\n",
        "\r\n",
        "$$X = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\dots \\\\ x_D \\end{bmatrix}; y = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_D \\end{bmatrix} $$\r\n",
        "\r\n",
        "$$ L(w) = (y - Xw)^\\top (y - Xw)$$\r\n",
        "$$ = y^\\top y - 2w^\\top X^\\top y + w^\\top X^\\top X w $$\r\n",
        "\r\n",
        "Now we can compute the gradient:\r\n",
        "\r\n",
        "$$ \\frac{\\delta L}{\\delta w} = \\frac{\\delta}{\\delta w} ( y^\\top y - 2w^\\top X^\\top y + w^\\top X^\\top X w ) $$\r\n",
        "$$ = -2X^\\top y + 2 X^\\top X w $$\r\n",
        "\r\n",
        "Now let's solve for $w$ when the gradient is zero:\r\n",
        "\r\n",
        "$$ -2X^\\top y + 2 X^\\top X w = 0 $$\r\n",
        "$$ X^\\top X w = X^\\top y $$\r\n",
        "$$ w^* = (X^\\top X)^{-1} X^\\top Y $$\r\n",
        "\r\n",
        "We now have a formula for the optimal value $w^*$ of the weights given the data.\r\n",
        "\r\n",
        "**(exercise)** Write a function that appends 1 to each data point, then write a function that computes the optimal weights according to this formula. You might find `np.transpose()`, `np.matmul()`, and `np.linalg.inv()` useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-DDk8aoD4h"
      },
      "source": [
        "# write code for computing the optimal regression weights for the dataset\r\n",
        "def append_ones(Xs):\r\n",
        "  raise NotImplementedError\r\n",
        "\r\n",
        "def compute_weights(Xs, ys):\r\n",
        "  tmp1 = np.linalg.inv(np.matmul(np.transpose(Xs), Xs))\r\n",
        "  tmp2 = np.matmul(np.transpose(Xs), ys)\r\n",
        "  raise NotImplementedError\r\n",
        "\r\n",
        "X_new = append_ones(X)\r\n",
        "w_star = compute_w(X_new, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6taUKoKzviK"
      },
      "source": [
        "Now that we can compute the optimal weights, we can do so on our dataset. However, we don't just care about how well our model does on our data, but also any future data we might receive. In order to see how well our learned model performs on future data, we can split up our dataset into a **training set** and a **test set**. \r\n",
        "\r\n",
        "**(exercise)** Let's write a function to reserve 20% of the data for testing, and then compute the optimal weights on the remaining 80% of the data. \r\n",
        "\r\n",
        "What is the value of the bias term $b$ the model learns?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK5l9Zm2zw1g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPjVbQHEoEIm"
      },
      "source": [
        "\r\n",
        "## Evaluation\r\n",
        "\r\n",
        "Now that we have a model, let's evaluate how good our model is.\r\n",
        "Again, we need some sense of what counts as good, so we will use the RSS to define good (lower RSS is better). However, since RSS is a sum, it will naturally be higher when we evaluate on more data, so let's instead compute the mean squared error (MSE) over examples. MSE is the following:\r\n",
        "\r\n",
        "$$ MSE = \\frac{1}{D||} \\sum_{i = 1}^{|D|} (y - w \\cdot x)^2 $$\r\n",
        "\r\n",
        "\r\n",
        "**(exercise)** Write a function to compute MSE, then compute the MSE for $w^*$ on the training data and the test data.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb2guYTuoJ4M",
        "outputId": "877e41e0-40f1-4a4d-ea33-38d03f587649"
      },
      "source": [
        "# write code for evaluating the RSS of the model predictions versus the actual target on the test set\r\n",
        "\r\n",
        "def mse(w, X, y):\r\n",
        "  raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train error: 0.5355338064877694\n",
            "Test error: 0.4946848356382133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SELIct973E0s"
      },
      "source": [
        "A nice property of a linear model is that the weights are interpretable: We can look at the magnitude of the weights for each feature to get a sense of which features are most influential in predicting the output.\n",
        "\n",
        "**(exercise)** Write code to look at the learned weights and determine which features the model puts the highest weight on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji_wvUp33qXK"
      },
      "source": [
        "# write code for looking at the weights to see the importance of each feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95SfLBiTnb9u"
      },
      "source": [
        "# PyTorch\n",
        "\n",
        "The material in this section is borrowed from [here](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "\n",
        "**What is PyTorch?**\n",
        "\n",
        "PyTorch is a Python-based scientific computing package serving two broad purposes:\n",
        "* A replacement for NumPy to use the power of GPUs and other accelerators.\n",
        "* An automatic differentiation library that is useful to implement neural networks.\n",
        "\n",
        "**Goal of this tutorial:**\n",
        "\n",
        "Understand PyTorch’s Tensor library and neural networks at a high level.\n",
        "Train a small neural network to classify images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDl9sXELx3XQ"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other specialized hardware to accelerate computing. If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along in this quick API walkthrough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cufYkqoix_lT"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrG3ItA8yARk"
      },
      "source": [
        "### Tensor Initialization\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is automatically inferred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBkIzWteyJqn"
      },
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqozxiGjyKqv"
      },
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQX68gs6yTLF"
      },
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGz7Ex5wyWt8"
      },
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOh5LkoqyZ5S"
      },
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bHbzKH2ycCM"
      },
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuHfrDrQyiE1"
      },
      "source": [
        "### Tensor Attributes\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5wNEGQ8ylDz"
      },
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3R783B6ylzM"
      },
      "source": [
        "### Tensor Operations\n",
        "\n",
        "Over 100 tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random sampling, and more are comprehensively described here.\n",
        "\n",
        "Each of them can be run on the GPU (at typically higher speeds than on a CPU). If you’re using Colab, allocate a GPU by going to Edit > Notebook Settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vERXB6n0yqYJ"
      },
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFbl5lUHyrDM"
      },
      "source": [
        "Try out some of the operations from the list. If you’re familiar with the NumPy API, you’ll find the Tensor API a breeze to use.\n",
        "\n",
        "**Standard numpy-like indexing and slicing:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etlzxjJuywV8"
      },
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peBOM6_Wyw0v"
      },
      "source": [
        "**Joining tensors** You can use torch.cat to concatenate a sequence of tensors along a given dimension. See also torch.stack, another tensor joining op that is subtly different from torch.cat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnM7q14Fy1OP"
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7cHyirby4EP"
      },
      "source": [
        "**Multiplying tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxqQjiehy7Df"
      },
      "source": [
        "# This computes the element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5CT5Xmy74m"
      },
      "source": [
        "This computes the matrix multiplication between two tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czIxXEJmy_oa"
      },
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yolxt60MzGYC"
      },
      "source": [
        "**In-place operations** Operations that have a _ suffix are in-place. For example: x.copy_(y), x.t_(), will change x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nZcFQggzJ-4"
      },
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMLDsc9ozO1R"
      },
      "source": [
        "### Bridge with NumPy\n",
        "\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.\n",
        "\n",
        "### Tensor to NumPy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kErWZIOfzVsi"
      },
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SK-BA-hzXwr"
      },
      "source": [
        "A change in the tensor reflects in the NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l8EgmHgzaV8"
      },
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOqQlG55zcGH"
      },
      "source": [
        "NumPy array to Tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTJD_1fVzem_"
      },
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMtuursEzgPs"
      },
      "source": [
        "Changes in the NumPy array reflects in the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaK015BzzjXg"
      },
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q_v5N-6znrr"
      },
      "source": [
        "## A Gentle Introduction To `torch.autograd`\n",
        "\n",
        "`torch.autograd` is PyTorch’s automatic differentiation engine that powers neural network training. In this section, you will get a conceptual understanding of how autograd helps a neural network train.\n",
        "\n",
        "### Background\n",
        "\n",
        "Neural networks (NNs) are a collection of nested functions that are executed on some input data. These functions are defined by parameters (consisting of weights and biases), which in PyTorch are stored in tensors.\n",
        "\n",
        "Training a NN happens in two steps:\n",
        "\n",
        "**Forward Propagation:** In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.\n",
        "\n",
        "**Backward Propagation:** In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the functions (gradients), and optimizing the parameters using gradient descent. For a more detailed walkthrough of backprop, [check out this video from 3Blue1Brown](https://www.youtube.com/watch?v=tIeHLnjs5U8)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHAxRnEd01GJ"
      },
      "source": [
        "### Differentiation in Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8hxDwYJ02vi"
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtt0San-04cf"
      },
      "source": [
        "We create another tensor Q from a and b.\n",
        "\n",
        "$Q=3a^{3} - b^{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG-9-MgE1B5X"
      },
      "source": [
        "Q = 3*a**3 - b**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWBl1eNU1CXj"
      },
      "source": [
        "Let’s assume a and b to be parameters of an NN, and Q to be the error. In NN training, we want gradients of the error w.r.t. parameters, i.e.\n",
        "\n",
        "$\\frac{\\partial Q}{\\partial a} = 9a^{2}$\n",
        "\n",
        "$\\frac{\\partial Q}{\\partial b} = -2b$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ7kMPii1gcd"
      },
      "source": [
        "When we call .backward() on Q, autograd calculates these gradients and stores them in the respective tensors’ .grad attribute.\n",
        "\n",
        "We need to explicitly pass a gradient argument in Q.backward() because it is a vector. gradient is a tensor of the same shape as Q, and it represents the gradient of Q w.r.t. itself, i.e.\n",
        "\n",
        "$\\frac{\\partial Q}{\\partial Q} = 1$\n",
        "\n",
        "Equivalently, we can also aggregate Q into a scalar and call backward implicitly, like Q.sum().backward().\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7SVrSFz1r8H"
      },
      "source": [
        "external_grad = torch.tensor([1., 1.])\n",
        "Q.backward(gradient=external_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUx2vXcS1uPG"
      },
      "source": [
        "Gradients are now deposited in a.grad and b.grad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqTMDgjU1vz1"
      },
      "source": [
        "# check if collected gradients are correct\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}